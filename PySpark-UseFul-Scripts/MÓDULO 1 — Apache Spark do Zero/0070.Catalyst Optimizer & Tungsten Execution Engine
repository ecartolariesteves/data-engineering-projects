Catalyst Optimizer:

√â o motor de otimiza√ß√£o de consultas do Spark.
Pega seu c√≥digo DataFrame/SQL e cria um plano l√≥gico otimizado, depois transforma num plano f√≠sico eficiente.
Faz coisas como:

Reordena√ß√£o de filtros (predicate pushdown).
Combinar opera√ß√µes.
Remover colunas n√£o usadas (column pruning).

Tungsten Engine:
Otimiza uso de mem√≥ria e c√≥digo gerado.
Usa off-heap memory e gera√ß√£o de bytecode.

üìå Moral da hist√≥ria: Se poss√≠vel, sempre use DataFrame API ou SQL, n√£o RDD puro, porque s√≥ assim voc√™ ganha o poder do Catalyst.


# Ver n√∫mero de parti√ß√µes
print("Parti√ß√µes atuais:", df.rdd.getNumPartitions())

# Reparticionar (aumenta o paralelismo)
df_repart = df.repartition(4)

# Coalesce (reduz parti√ß√µes sem shuffle)
df_coalesce = df.coalesce(1)

 Regra geral:

Dados grandes ‚Üí aumentar parti√ß√µes (repartition).
Resultados pequenos para salvar ‚Üí reduzir (coalesce(1)).

Minimizar Shuffles
Shuffle = redistribuir dados entre parti√ß√µes (ex.: join, groupBy).
√â caro porque envolve rede e disco.

# Exemplo ruim (gera shuffle desnecess√°rio)
df.groupBy("categoria").count().filter(col("count") > 2).show()

# Melhor: filtrar antes do groupBy
df.filter(col("valor") > 100).groupBy("categoria").count().show()

Broadcast Join
Quando uma das tabelas √© pequena, podemos mandar ela inteira pra todos os executors e evitar shuffle.

from pyspark.sql.functions import broadcast

df_info = spark.createDataFrame(
    [("A", "Tipo 1"), ("B", "Tipo 2"), ("C", "Tipo 3")],
    ["categoria", "descricao"]
)

# Join otimizado
df.join(broadcast(df_info), "categoria").show()

Cache & Persist√™ncia
Se voc√™ for reusar o mesmo DataFrame em m√∫ltiplas opera√ß√µes, vale a pena cachear.

# Cache em mem√≥ria
df.cache()

# Cache em mem√≥ria + disco
from pyspark import StorageLevel
df.persist(StorageLevel.MEMORY_AND_DISK)

# Limpar cache
df.unpersist()

# N√£o cache tudo ‚Äî s√≥ se for realmente reutilizar v√°rias vezes.

Monitoramento no Spark UI
Ao rodar Spark local, acesse:
http://localhost:4040

Voc√™ ver√°:
    Jobs, Stages, Tasks
    Tempo gasto em cada etapa
    Uso de mem√≥ria
    Tamanho de shuffle

spark = SparkSession.builder \
    .appName("TuningExample") \
    .config("spark.sql.shuffle.partitions", "8") \  # padr√£o √© 200!
    .config("spark.executor.memory", "2g") \
    .getOrCreate()

# Dica: spark.sql.shuffle.partitions √© um dos ajustes mais importantes.
  Para datasets pequenos/m√©dios, 200 parti√ß√µes √© exagero.

  